{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸš– NYC Taxi Fare Prediction\n",
        "\n",
        "## ðŸ“Œ Overview  \n",
        "This project predicts the **fare amount of New York City taxi rides** using machine learning regression models.  \n",
        "The dataset includes pickup/drop-off coordinates, time, and passenger count. By applying **feature engineering** (distance calculation, pickup time, day of week), we train multiple models and compare their performance.  \n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ› ï¸ Tech Stack  \n",
        "- Python  \n",
        "- Pandas, NumPy  \n",
        "- Matplotlib, Seaborn  \n",
        "- Scikit-learn (Linear Regression, Decision Tree, Random Forest, Gradient Boosting)  \n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“Š Dataset  \n",
        "- **Source:** TaxiFare.csv (50,000 entries)  \n",
        "- **Features before preprocessing:**  \n",
        "  - `unique_id`  \n",
        "  - `amount` (target variable)  \n",
        "  - `date_time_of_pickup`  \n",
        "  - `longitude_of_pickup`, `latitude_of_pickup`  \n",
        "  - `longitude_of_dropoff`, `latitude_of_dropoff`  \n",
        "  - `no_of_passenger`  \n",
        "\n",
        "---\n",
        "\n",
        "## ðŸš€ Project Workflow  \n",
        "1. **Data Preprocessing**  \n",
        "   - Removed `unique_id` and filtered single-passenger rides.  \n",
        "   - Dropped invalid distances/fare values (outliers).  \n",
        "   - Engineered new features:  \n",
        "     - `day_of_week` (0=Monday,â€¦,6=Sunday)  \n",
        "     - `pickup_time` (hour of day)  \n",
        "     - `distance` (calculated using longitude/latitude differences).  \n",
        "\n",
        "2. **Feature Selection**  \n",
        "   - Final features: `day_of_week`, `pickup_time`, `distance`.  \n",
        "   - Target: `amount` (fare).  \n",
        "\n",
        "3. **Model Training**  \n",
        "   - **Linear Regression**  \n",
        "   - **Decision Tree Regressor**  \n",
        "   - **Random Forest Regressor**  \n",
        "   - **Gradient Boosting Regressor**  \n",
        "\n",
        "4. **Evaluation**  \n",
        "   - Compared RÂ² Score (model performance).  \n",
        "   - Calculated Mean Absolute Error (MAE).  \n",
        "\n",
        "---\n",
        "\n",
        "## ðŸ“ˆ Results  \n",
        "\n",
        "| Model                   | RÂ² Score | MAE   |\n",
        "|--------------------------|----------|-------|\n",
        "| Linear Regression        | 0.72     | 2.42  |\n",
        "| Decision Tree Regressor  | 0.48     | 3.33  |\n",
        "| Random Forest Regressor  | 0.70     | 2.55  |\n",
        "| Gradient Boosting Regr.  | **0.75** | **2.29** |\n",
        "\n",
        "âœ… **Gradient Boosting Regressor** performed the best.  \n",
        "\n",
        "Example predictions for `[day_of_week=4, pickup_time=17, distance=2.0 miles]` :  \n",
        "- Linear Regression â†’ **$10.75**  \n",
        "- Decision Tree â†’ **$19.50**  \n",
        "- Random Forest â†’ **$16.09**  \n",
        "- Gradient Boosting â†’ **$11.67**  \n",
        "\n",
        "---\n",
        "\n",
        "## â–¶ï¸ How to Run  \n",
        "```bash\n",
        "# Install dependencies\n",
        "pip install pandas numpy matplotlib seaborn scikit-learn\n",
        "\n",
        "# Run the notebook\n",
        "jupyter notebook taxifare_prediction.ipynb\n"
      ],
      "metadata": {
        "id": "TQvbx16iUuHL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "df = pd.read_csv('/content/TaxiFare (3).csv')\n",
        "df.head()\n",
        "\n",
        "df.shape\n",
        "\n",
        "df.info()\n",
        "\n",
        "sns.countplot(x=df['no_of_passenger'])\n",
        "\n",
        "df = df[df['no_of_passenger'] == 1]\n",
        "df = df.drop(['unique_id', 'no_of_passenger'], axis=1)\n",
        "df.head()\n",
        "\n",
        "df.shape\n",
        "\n",
        "corr_matrix = df.corr()\n",
        "corr_matrix['amount'].sort_values(ascending=False)\n",
        "\n",
        "import datetime\n",
        "from math import sqrt\n",
        "\n",
        "for i, row in df.iterrows():\n",
        "    dt = datetime.datetime.strptime(row['date_time_of_pickup'], '%Y-%m-%d %H:%M:%S UTC')\n",
        "    df.at[i, 'day_of_week'] = dt.weekday()\n",
        "    df.at[i, 'pickup_time'] = dt.hour\n",
        "    x = (row['longitude_of_dropoff'] - row['longitude_of_pickup']) * 54.6 # 1 degree == 54.6 miles\n",
        "    y = (row['latitude_of_dropoff'] - row['latitude_of_pickup']) * 69.0   # 1 degree == 69 miles\n",
        "    distance = sqrt(x**2 + y**2)\n",
        "    df.at[i, 'distance'] = distance\n",
        "\n",
        "df.head()\n",
        "\n",
        "df.drop(columns=['date_time_of_pickup', 'longitude_of_pickup', 'latitude_of_pickup', 'longitude_of_dropoff', 'latitude_of_dropoff'], inplace=True)\n",
        "df.head()\n",
        "\n",
        "corr_matrix = df.corr()\n",
        "corr_matrix[\"amount\"].sort_values(ascending=False)\n",
        "\n",
        "df.describe\n",
        "\n",
        "df = df[(df['distance'] > 1.0) & (df['distance'] < 10.0)]\n",
        "df = df[(df['amount'] > 0.0) & (df['amount'] < 50.0)]\n",
        "df.shape\n",
        "\n",
        "corr_matrix = df.corr()\n",
        "corr_matrix[\"amount\"].sort_values(ascending=False)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x = df.drop(['amount'], axis=1)\n",
        "y = df['amount']\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "model = LinearRegression()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "decision_tree_model = DecisionTreeRegressor()\n",
        "decision_tree_model.fit(x_train, y_train)\n",
        "\n",
        "from sklearn.ensemble import RandomForestRegressor ,GradientBoostingRegressor\n",
        "\n",
        "random_forest_model = RandomForestRegressor()\n",
        "random_forest_model.fit(x_train, y_train)\n",
        "\n",
        "model1 = GradientBoostingRegressor()\n",
        "model1.fit(x_train, y_train)\n",
        "\n",
        "print(\"Linear regression:\", model.score(x_test, y_test))\n",
        "print(\"Decision tree:\", decision_tree_model.score(x_test, y_test))\n",
        "print(\"Random forest:\", random_forest_model.score(x_test, y_test))\n",
        "print(\"Gradient boosting:\", model1.score(x_test, y_test))\n",
        "\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "\n",
        "print(\"Linear regression mae:\",mean_absolute_error(y_test, model.predict(x_test)))\n",
        "print(\"Decision tree mae:\",mean_absolute_error(y_test, decision_tree_model.predict(x_test)))\n",
        "print(\"Random forest mae:\",mean_absolute_error(y_test, random_forest_model.predict(x_test)))\n",
        "print(\"Gradient boosting mae:\",mean_absolute_error(y_test, model1.predict(x_test)))\n",
        "\n",
        "print(\"Linear regression:\", model.predict([[4, 17, 2.0]]))\n",
        "print(\"Decision tree:\", decision_tree_model.predict([[4, 17, 2.0]]))\n",
        "print(\"Random forest:\", random_forest_model.predict([[4, 17, 2.0]]))\n",
        "print(\"Gradient boosting:\", model1.predict([[4, 17, 2.0]]))\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "xo9JFTOCUxfl",
        "outputId": "dfeca6fd-d586-42f6-81ad-e27d28f91d6a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/TaxiFare (3).csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1157131068.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/TaxiFare (3).csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/TaxiFare (3).csv'"
          ]
        }
      ]
    }
  ]
}